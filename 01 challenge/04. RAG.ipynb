{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RAG\n",
    "- Stuff Documents 체인을 사용하여 완전한 RAG 파이프라인을 구현하세요.\n",
    "- 체인을 수동으로 구현해야 합니다.\n",
    "- 체인에 `ConversationBufferMemory`를 부여합니다.\n",
    "- 이 문서를 사용하여 RAG를 수행하세요: files/chapter_one.txt\n",
    "- 체인에 다음 질문을 합니다:\n",
    "    - Aaronson 은 유죄인가요?\n",
    "    - 그가 테이블에 어떤 메시지를 썼나요?\n",
    "    - Julia 는 누구인가요?\n",
    "\"\"\"\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import requests\n",
    "\n",
    "# 문서 다운로드 및 저장\n",
    "def download_document(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "# 문서 URL\n",
    "doc_url = \"https://gist.githubusercontent.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223/raw/960d183b262b0755bba4850f4729806fe9c0915c/chapter_one.txt\"\n",
    "doc_path = \"./chapter_one.txt\"\n",
    "download_document(doc_url, doc_path)\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# 문서 로더 및 스플리터 설정\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = UnstructuredFileLoader(doc_path)\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# 임베딩 설정\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# Vector Store 생성\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 메모리 설정\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"question\",\n",
    "    output_key=\"answer\",\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"You are a helpful AI assistant. Answer questions based on the following context and chat history. \n",
    "        If you don't know the answer, just say you don't know. Don't make up answers.\n",
    "        \n",
    "        Context: {context}\n",
    "        \n",
    "        Chat History: {chat_history}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# Chain 구성\n",
    "chain = {\n",
    "    \"context\": retriever,\n",
    "    \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"],\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | prompt | llm\n",
    "\n",
    "# 질문 함수 정의\n",
    "def ask_question(question):\n",
    "    response = chain.invoke(question)\n",
    "    # 메모리에 대화 저장\n",
    "    memory.save_context(\n",
    "        {\"question\": question},\n",
    "        {\"answer\": response.content}\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "# 테스트 질문\n",
    "questions = [\n",
    "    \"Aaronson 은 유죄인가요?\",\n",
    "    \"그가 테이블에 어떤 메시지를 썼나요?\",\n",
    "    \"Julia 는 누구인가요?\"\n",
    "]\n",
    "\n",
    "# 질문 실행\n",
    "print(\"=== RAG 테스트 시작 ===\\\\n\")\n",
    "for question in questions:\n",
    "    print(f\"질문: {question}\")\n",
    "    answer = ask_question(question)\n",
    "    print(f\"답변: {answer}\\\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
