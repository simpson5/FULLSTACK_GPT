# LangChainì˜ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì„í¬íŠ¸
from langchain.chat_models import ChatOpenAI  # ChatGPT APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤
from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate  # Few-shot í•™ìŠµì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
from langchain.callbacks import StreamingStdOutCallbackHandler  # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì½œë°±
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder  # ì±„íŒ… í”„ë¡¬í”„íŠ¸ ê´€ë ¨ í´ë˜ìŠ¤ë“¤
from langchain.memory import ConversationSummaryBufferMemory  # ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì €ì¥í•˜ëŠ” ë©”ëª¨ë¦¬
from langchain.schema.runnable import RunnablePassthrough  # ì²´ì¸ êµ¬ì„±ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹°

# ChatGPT ëª¨ë¸ ì´ˆê¸°í™”
chat = ChatOpenAI(
    temperature=0.1,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ì‘ë‹µ ìƒì„±
    streaming=True,   # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°›ê¸°
    callbacks=[
        StreamingStdOutCallbackHandler(),  # ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥
    ],
)

# ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì €ì¥í•˜ëŠ” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
summary_memory = ConversationSummaryBufferMemory(
    llm=chat,  # ìš”ì•½ì— ì‚¬ìš©í•  ì–¸ì–´ ëª¨ë¸
    memory_key="history",  # ë©”ëª¨ë¦¬ë¥¼ ì°¸ì¡°í•  ë•Œ ì‚¬ìš©í•  í‚¤
    return_messages=True   # ë©”ì‹œì§€ ê°ì²´ í˜•íƒœë¡œ ë°˜í™˜
)

# Few-shot í•™ìŠµì„ ìœ„í•œ ì˜ˆì‹œ ë°ì´í„°
examples = [
    {
        "movie": "Express topgun with 3 icons and explain",
        "answer": """
                ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥
                ì²« ë²ˆì§¸ ì•„ì´ì½˜ì€ íƒ‘ê±´ì˜ ë¹„í–‰ê¸°ë¥¼ ë‚˜íƒ€ë‚´ë©°, ë‘ ë²ˆì§¸ ì•„ì´ì½˜ì€ íƒ‘ê±´ì˜ íŒŒì¼ëŸ¿ì„ ë‚˜íƒ€ë‚´ë©°, ì„¸ ë²ˆì§¸ ì•„ì´ì½˜ì€ ë¹„í–‰ê¸° ì „íˆ¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
        """,
    },
    {
        "movie": "Express godzilla with 3 icons and explain",
        "answer": """
                ğŸ¦–ğŸ”¥ğŸ‘‘
                ì²« ë²ˆì§¸ ì•„ì´ì½˜ì€ ê³ ì§€ë¼ì˜ ëª¨ìŠµì„ ë‚˜íƒ€ë‚´ë©°, ë‘ ë²ˆì§¸ ì•„ì´ì½˜ì€ ê³ ì§€ë¼ì˜ ë¶ˆê½ƒì„ ë‚˜íƒ€ë‚´ë©°, ì„¸ ë²ˆì§¸ ì•„ì´ì½˜ì€ ê³ ì§€ë¼ì˜ ì™•ê´€ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
        """,
    },
]

# ê° ì˜ˆì‹œë¥¼ ìœ„í•œ ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
example_prompt = ChatPromptTemplate.from_messages(
    [
        ("human", "Express {movie} with 3 icons and explain"),
        ("ai", "{answer}"),
    ]
)

# Few-shot í•™ìŠµì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
example_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)

# ìµœì¢… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±
final_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a movie expert. Here are some examples of how you talk. and answer in Korean."),  # ì‹œìŠ¤í…œ ì—­í•  ì •ì˜
        example_prompt,  # Few-shot ì˜ˆì‹œë“¤
        MessagesPlaceholder(variable_name="history"),  # ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
        ("human", "{question}"),  # ì‚¬ìš©ì ì…ë ¥
    ]
)

# ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ë‚´ìš©ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def load_memory(_):
    return summary_memory.load_memory_variables({})["history"]

# ì²´ì¸ êµ¬ì„±: ë©”ëª¨ë¦¬ ë¡œë“œ -> í”„ë¡¬í”„íŠ¸ ìƒì„± -> ì±—ë´‡ ì‘ë‹µ
chain = RunnablePassthrough.assign(history=load_memory) | final_prompt | chat

# ì²´ì¸ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def invoke_chain(question):
    # ì²´ì¸ ì‹¤í–‰
    result = chain.invoke({"question": question})
    # ëŒ€í™” ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
    summary_memory.save_context(
        {"input": question},
        {"output": result.content},
    )
    print(result)