### Tiktoken을 활용한 토큰 기반 텍스트 분할

#### 토큰화(Tokenization)의 이해
토큰화는 텍스트를 LLM이 처리할 수 있는 단위로 변환하는 과정입니다.

##### 문자 vs 토큰
- **문자 기반 길이 계산**: Python의 기본 `len()` 함수 사용
  - 예: "ABCD" → 4 characters
- **토큰 기반 길이 계산**: LLM의 실제 토큰 처리 방식
  - 한 토큰이 여러 문자를 포함할 수 있음
  - 한 단어가 여러 토큰으로 분할될 수 있음

##### 토큰화 예시
```
입력: "hello everyone my name is nicolas"
- 문자 수: 32
- 토큰 수: 13

토큰 분할 예시:
- "hello" → 1 토큰
- "everyone" + 공백 → 1 토큰
- "nicolas" → "nic" + "olas" (2 토큰)
```

#### Tiktoken 활용
Tiktoken은 OpenAI가 제공하는 토큰화 라이브러리입니다.

##### 특징
- OpenAI 모델이 사용하는 것과 동일한 토큰화 방식 제공
- 정확한 토큰 수 계산 가능
- LangChain의 텍스트 분할기와 통합 가능

##### CharacterTextSplitter with Tiktoken
```python
from langchain.text_splitter import CharacterTextSplitter

splitter = CharacterTextSplitter.from_tiktoken_encoder(
    separator="\n",
    chunk_size=600,      # 토큰 단위의 청크 크기
    chunk_overlap=100    # 토큰 단위의 중복 크기
)

loader = UnstructuredFileLoader("./files/chapter_one.docx")
```

#### Tiktoken 사용의 장점
1. **정확한 토큰 계산**
   - 모델이 실제로 처리하는 방식과 동일한 토큰 수 계산
   - 컨텍스트 윈도우 제한을 정확하게 관리 가능

2. **효율적인 청크 크기 관리**
   - 토큰 기반으로 청크 크기 설정
   - 모델의 최대 토큰 제한을 고려한 분할 가능

3. **비용 최적화**
   - 정확한 토큰 수 예측으로 API 비용 관리 용이
   - 불필요한 토큰 낭비 방지

#### 실제 적용 시 고려사항
- 토큰 기반 분할이 항상 의미 단위와 일치하지 않을 수 있음
- 문서의 특성에 따라 적절한 chunk_size 조정 필요
- 토큰 수와 의미 보존 사이의 균형 고려

#### 다음 단계
- 임베딩(Embedding) 생성
- Vector Store 구성
- 의미 기반 검색 구현 