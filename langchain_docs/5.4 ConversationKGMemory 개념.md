### ConversationKGMemory 개념

- **개요**
  - 대화에서 엔티티(개체)를 추출하여 지식 그래프 구성
  - LLM을 사용해 엔티티 간의 관계를 추출하고 저장
  - 특정 엔티티에 대한 정보를 구조화하여 검색 가능

- **동작 방식**
  - 대화 내용에서 주요 엔티티 추출
  - 엔티티 간의 관계를 LLM으로 분석
  - 지식 그래프 형태로 정보 저장
  - 질문에 따라 관련 엔티티 정보 검색

- **구현 예시**
  ```python
  from langchain.memory import ConversationKGMemory
  from langchain.chat_models import ChatOpenAI
  
  # LLM 설정
  llm = ChatOpenAI(temperature=0.1)
  
  # 메모리 초기화
  memory = ConversationKGMemory(llm=llm)
  
  # 대화 추가
  memory.save_context(
      {"input": "Hi I'm Nicolas living in South Korea"},
      {"output": "Nice to meet you Nicolas!"}
  )
  
  memory.save_context(
      {"input": "I like kimchi"},
      {"output": "That's great! Kimchi is delicious"}
  )
  
  # 특정 엔티티에 대한 정보 검색
  memory.load_memory_variables({"input": "What do you know about Nicolas?"})
  # 결과: "Nicolas is a person. Nicolas lives in South Korea. Nicolas likes kimchi."
  ```

- **장점**
  - 구조화된 정보 저장
  - 엔티티 중심의 정보 검색
  - 관계 기반 지식 표현
  - 특정 주제/개체에 대한 정보 추적 용이

- **단점**
  - LLM 호출 비용 발생
  - 엔티티 추출 정확도에 의존
  - 비구조화된 대화 처리의 한계
  - 복잡한 관계 표현의 어려움

- **활용 사례**
  - 개인화된 정보 관리
  - 사용자 프로필 구축
  - 지식 베이스 구축
  - FAQ/QA 시스템

- **주의사항**
  - 엔티티 추출 품질
    - LLM의 성능에 의존
    - 도메인별 튜닝 필요
  - 메모리 관리
    - 그래프 크기 제한 고려
    - 중요 관계 보존
  - 비용 효율성
    - LLM 호출 최적화
    - 캐싱 전략 수립

---
참조:
- https://python.langchain.com/docs/modules/memory/types/kg
- https://python.langchain.com/docs/modules/memory/types/entity_summary 